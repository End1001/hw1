{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcKSqqwMufOx"
      },
      "source": [
        "# **HOMEWORK 1 - Regressione Lineare**\n",
        "\n",
        "In questo homework dovrete:\n",
        "\n",
        "1. Scrivere una funzione di pipeline che deve gestire l' allenamento di un modello di regressione lineare al variare degli iperparametri forniti. Nello specifico:\n",
        "    * Deve applicare la PCA, se presente.\n",
        "    \n",
        "    * Deve applicare la standardizzazione, se presente.\n",
        "\n",
        "    * Deve applicare la regolarizzazione, se presente.\n",
        "\n",
        "    * Deve allenare il modello di regressione lineare.\n",
        "\n",
        "    * Deve calcolare la MAE.\n",
        "\n",
        "2. Scrivere una funzione che utilizzi la `pipeline` definita al punto 1 e che testi tutte le configurazioni possibili presenti in `configs`. Nel dettaglio la funzione deve:\n",
        "    * Dividere il dataset in train e validation.\n",
        "\n",
        "    * Calcolare, grazie alla funzione `pipeline` definita al punto 1, quale configurazione ottiene il punteggio migliore (quale configurazione ha la MAE di validation più bassa).\n",
        "\n",
        "3. Scrivere una funzione che utilizzi la configurazione migliore prodotta dalla funzione definita al punto 2 e la testi sul test set.\n",
        "\n",
        "4. Stampare:\n",
        "    * La migliore configurazione\n",
        "\n",
        "    * Il miglior MAE di validation\n",
        "\n",
        "    * Il migliore MAE di train\n",
        "\n",
        "    * Il MAE di test\n",
        "\n",
        "\n",
        "Il codice che di seguito trovate già fornito deve essere utilizzato per la risoluzione dell' homework, **NON MODIFICATELO IN ALCUN MODO**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH9mWdhgufO0"
      },
      "source": [
        "*testo in corsivo*## **Dataset Wine Quality White**\n",
        "\n",
        "Il dataset da utilizzare è `wine-quality-white` della libreria `scikit-learn`. Il dataset contiene 11 variabili numeriche + 1 di target che classifica il vino in diverse categorie di qualità. Per il nostro obiettivo la variabile di target è considerata come `float`, permettendoci di applicare la regressione lineare. All' interno del dataset sono contenuti 4898 campioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2SXk2FUufO0"
      },
      "outputs": [],
      "source": [
        "# Questa cella contiene tutte le librerie di cui necessitate per risolvere l' homework.\n",
        "# Ricordate di eseguirla prima di iniziare.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHunOnQmufO1",
        "outputId": "a7b5cc34-4317-4aa3-f8e3-f1ec8799d771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di combinazioni: 56\n"
          ]
        }
      ],
      "source": [
        "hyperparams = {\n",
        "    # PCA\n",
        "    'use_pca': [True, False],\n",
        "    'pca_standardize': [True, False],\n",
        "    'pca_components': [3, 5, 10],\n",
        "    # Data standardization\n",
        "    'data_standardize': [True, False],\n",
        "    # Regularization l2\n",
        "    'use_regularization': [True, False],\n",
        "    'reg_lambda': [0.1, 1, 10],\n",
        "}\n",
        "\n",
        "# Calcoliamo tutte le possibili combinazioni di iperparametri\n",
        "import itertools\n",
        "combinations = list(itertools.product(*hyperparams.values()))\n",
        "configs = [dict(zip(hyperparams.keys(), combination)) for combination in combinations]\n",
        "\n",
        "# Evitiamo le combinazioni non valide\n",
        "for config in configs:\n",
        "    if not config['use_pca']:\n",
        "        config['pca_standardize'] = None\n",
        "        config['pca_components'] = None\n",
        "    if not config['use_regularization']:\n",
        "        config['reg_lambda'] = None\n",
        "configs = set([tuple(config.items()) for config in configs])\n",
        "\n",
        "# Convertiamo di nuovo in lista di dizionari\n",
        "configs = [dict(config) for config in configs]\n",
        "print(f'Numero di combinazioni: {len(configs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTeKf-vBufO1"
      },
      "source": [
        "In `configs` avete una lista di dizionari, ogni dizionario contiene una possibile combinazione di hyperparametri da utilizzare nella fase di training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OR3_67mufO1",
        "outputId": "6e680c02-b4bd-449c-8888-7f0cb6733dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensioni dataset:\n",
            "- Total: 4898 campioni\n",
            "- Training: 3134 (64.0%)\n",
            "- Validation: 784 (16.0%)\n",
            "- Test: 980 (20.0%)\n",
            "\n",
            "Miglior configurazione:\n",
            "- use_pca: True\n",
            "- pca_standardize: True\n",
            "- pca_components: 10\n",
            "- data_standardize: False\n",
            "- use_regularization: False\n",
            "- reg_lambda: None\n",
            "\n",
            "MAE training: 0.5842\n",
            "MAE validation: 0.5867\n",
            "MAE test: 0.5968\n",
            "\n",
            "MAE test finale (train+val): 0.5958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Carica il dataset da OpenML\n",
        "data = fetch_openml(name='wine-quality-white', version=1, as_frame=True)\n",
        "X = data.data  # Features del dataset\n",
        "y = data.target.astype(float)  # Target convertito in float per regressione\n",
        "\n",
        "def pipeline(X_train, y_train, X_val, y_val, hyperparams):\n",
        "    \"\"\"Pipeline completa di preprocessing e regressione lineare\"\"\"\n",
        "    # Copia dei dati per evitare modifiche agli originali\n",
        "    X_train = X_train.copy()\n",
        "    X_val = X_val.copy()\n",
        "\n",
        "    # Sezione PCA: riduzione dimensionalità\n",
        "    if hyperparams['use_pca']:\n",
        "        # Standardizzazione prima di PCA se richiesto\n",
        "        if hyperparams['pca_standardize']:\n",
        "            scaler = StandardScaler()\n",
        "            X_train = scaler.fit_transform(X_train)  # Fit solo sul train\n",
        "            X_val = scaler.transform(X_val)  # Transform su validation\n",
        "\n",
        "        # Applica PCA con numero componenti specificato\n",
        "        n_components = hyperparams['pca_components']\n",
        "        pca = PCA(n_components)\n",
        "        X_train = pca.fit_transform(X_train)  # Fit solo sul train\n",
        "        X_val = pca.transform(X_val)  # Transform su validation\n",
        "\n",
        "    # Standardizzazione generale dei dati se richiesta\n",
        "    if hyperparams['data_standardize']:\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "    # Aggiunta colonna di 1 per il termine bias\n",
        "    array_train = np.ones((X_train.shape[0], 1))\n",
        "    array_validation = np.ones((X_val.shape[0], 1))\n",
        "    array_train_c = np.c_[array_train, X_train]  # Concatenazione colonna di 1\n",
        "    array_validation_c = np.c_[array_validation, X_val]\n",
        "\n",
        "    # Regressione lineare con/senza regolarizzazione L2\n",
        "    if hyperparams['use_regularization']:\n",
        "        # Calcolo coefficienti con regolarizzazione\n",
        "        X_transpose = array_train_c.T\n",
        "        X_transpose_X = X_transpose @ array_train_c\n",
        "        I = np.eye(X_transpose_X.shape[0])\n",
        "        I[0, 0] = 0  # Non regolarizzare il termine bias\n",
        "        X_transpose_X_inv = np.linalg.inv(X_transpose_X + hyperparams['reg_lambda'] * I)\n",
        "        beta = X_transpose_X_inv @ X_transpose @ y_train\n",
        "    else:\n",
        "        # Calcolo coefficienti senza regolarizzazione\n",
        "        X_transpose = array_train_c.T\n",
        "        X_transpose_X_inv = np.linalg.pinv(X_transpose @ array_train_c)\n",
        "        beta = X_transpose_X_inv @ X_transpose @ y_train\n",
        "\n",
        "    # Calcolo predizioni e Mean Absolute Error\n",
        "    y_train_pred = array_train_c @ beta\n",
        "    y_val_pred = array_validation_c @ beta\n",
        "    mae_train = np.mean(np.abs(y_train - y_train_pred))  # MAE train\n",
        "    mae_val = np.mean(np.abs(y_val - y_val_pred))  # MAE validation\n",
        "\n",
        "    return y_train_pred, y_val_pred, mae_train, mae_val, beta\n",
        "\n",
        "def Aux_func(X, y, train_split, val_split, test_split, configs):\n",
        "    \"\"\"Funzione principale per valutare diverse configurazioni\"\"\"\n",
        "    # Funzione per mescolare i dati\n",
        "    X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "    # Split iniziale 80% (train+val) - 20% test\n",
        "    n_samples = X.shape[0]\n",
        "    n_train_val = int(0.8 * n_samples)\n",
        "    X_train_val = X[:n_train_val]  # 80% iniziale\n",
        "    y_train_val = y[:n_train_val]\n",
        "    X_test = X[n_train_val:]  # 20% finale per test\n",
        "    y_test = y[n_train_val:]\n",
        "\n",
        "    # Split del train_val in 80% train - 20% validation\n",
        "    n_train = int(0.8 * X_train_val.shape[0])\n",
        "    X_train = X_train_val[:n_train]  # 80% di train_val (64% totale)\n",
        "    y_train = y_train_val[:n_train]\n",
        "    X_val = X_train_val[n_train:]  # 20% di train_val (16% totale)\n",
        "    y_val = y_train_val[n_train:]\n",
        "\n",
        "    # Inizializza variabili per miglior configurazione\n",
        "    best_config = None\n",
        "    best_mae_val = float('inf')\n",
        "    best_mae_train = float('inf')\n",
        "    best_beta = None\n",
        "    best_mae_test = float('inf')\n",
        "\n",
        "    # Valuta tutte le configurazioni di iperparametri\n",
        "    for config in configs:\n",
        "        # Valuta su train/validation\n",
        "        _, _, mae_train, mae_val, beta = pipeline(X_train.copy(), y_train.copy(),\n",
        "                                               X_val.copy(), y_val.copy(), config)\n",
        "\n",
        "        # Valuta su test set\n",
        "        _, _, _, mae_test, _ = pipeline(X_train.copy(), y_train.copy(),\n",
        "                                      X_test.copy(), y_test.copy(), config)\n",
        "\n",
        "        # Aggiorna miglior configurazione se necessario\n",
        "        if mae_val < best_mae_val:\n",
        "            best_mae_val = mae_val\n",
        "            best_mae_train = mae_train\n",
        "            best_config = config\n",
        "            best_beta = beta\n",
        "            best_mae_test = mae_test\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, best_config, best_mae_train, best_mae_val, best_beta, best_mae_test\n",
        "\n",
        "# Esecuzione principale\n",
        "results = Aux_func(X, y, train_split=0.8, val_split=0.2, test_split=0.2, configs=configs)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, best_config, best_mae_train, best_mae_val, best_beta, best_mae_test = results\n",
        "\n",
        "# Stampa risultati\n",
        "print(f\"\\nDimensioni dataset:\")\n",
        "print(f\"- Total: {X.shape[0]} campioni\")\n",
        "print(f\"- Training: {X_train.shape[0]} ({X_train.shape[0]/X.shape[0]:.1%})\")\n",
        "print(f\"- Validation: {X_val.shape[0]} ({X_val.shape[0]/X.shape[0]:.1%})\")\n",
        "print(f\"- Test: {X_test.shape[0]} ({X_test.shape[0]/X.shape[0]:.1%})\")\n",
        "\n",
        "print(\"\\nMiglior configurazione:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"- {k}: {v}\")\n",
        "\n",
        "print(f\"\\nMAE training: {best_mae_train:.4f}\")\n",
        "print(f\"MAE validation: {best_mae_val:.4f}\")\n",
        "print(f\"MAE test: {best_mae_test:.4f}\")\n",
        "\n",
        "# Valutazione finale su train+val completo\n",
        "X_full_train = np.vstack((X_train, X_val))  # Unisce train e validation\n",
        "y_full_train = np.concatenate((y_train, y_val))\n",
        "_, _, _, mae_test_final, _ = pipeline(X_full_train, y_full_train, X_test, y_test, best_config)\n",
        "print(f\"\\nMAE test finale (train+val): {mae_test_final:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}